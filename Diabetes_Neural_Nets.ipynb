{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes Neural Nets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN52kNb7OFhFuZ3XINRVxa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommycon/Diabetes-Readmission-Prediction/blob/master/Diabetes_Neural_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ5-a1HKxWco",
        "outputId": "75ff2559-6098-4293-a3bc-6f36e3726f94"
      },
      "source": [
        "!pip install texthero"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texthero\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/5a/a9d33b799fe53011de79d140ad6d86c440a2da1ae8a7b24e851ee2f8bde8/texthero-1.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from texthero) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.2.2)\n",
            "Collecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.6.0)\n",
            "Collecting unidecode>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.5.0)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.41.1)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.4.1)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (2.2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22->texthero) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22->texthero) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (4.0.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud>=1.5.0->texthero) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (50.3.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.0.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.4.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=0283bc8c8b1bd832fd866d8ad371b778f8d5cd90ccc5d8d1cd0b7a9b26c504c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk, unidecode, texthero\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5 texthero-1.0.9 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lj3f51F5flr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model\n",
        "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, Dropout, Activation\n",
        "from keras.optimizers import Adagrad\n",
        "np.random.seed(7)\n",
        "\n",
        "df = pd.read_csv('diabetic_data.csv')\n",
        "id_mapping = pd.read_csv('IDs_mapping.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "kSfAC9vC5pvg",
        "outputId": "312863f2-8595-4cf9-a4a2-8eb978c521f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>payer_code</th>\n",
              "      <th>medical_specialty</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>diag_1</th>\n",
              "      <th>diag_2</th>\n",
              "      <th>diag_3</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>max_glu_serum</th>\n",
              "      <th>A1Cresult</th>\n",
              "      <th>metformin</th>\n",
              "      <th>repaglinide</th>\n",
              "      <th>nateglinide</th>\n",
              "      <th>chlorpropamide</th>\n",
              "      <th>glimepiride</th>\n",
              "      <th>acetohexamide</th>\n",
              "      <th>glipizide</th>\n",
              "      <th>glyburide</th>\n",
              "      <th>tolbutamide</th>\n",
              "      <th>pioglitazone</th>\n",
              "      <th>rosiglitazone</th>\n",
              "      <th>acarbose</th>\n",
              "      <th>miglitol</th>\n",
              "      <th>troglitazone</th>\n",
              "      <th>tolazamide</th>\n",
              "      <th>examide</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2278392</td>\n",
              "      <td>8222157</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[0-10)</td>\n",
              "      <td>?</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>Pediatrics-Endocrinology</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.83</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149190</td>\n",
              "      <td>55629189</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[10-20)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>276</td>\n",
              "      <td>250.01</td>\n",
              "      <td>255</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64410</td>\n",
              "      <td>86047875</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>[20-30)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>648</td>\n",
              "      <td>250</td>\n",
              "      <td>V27</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500364</td>\n",
              "      <td>82442376</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[30-40)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>250.43</td>\n",
              "      <td>403</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16680</td>\n",
              "      <td>42519267</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[40-50)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>197</td>\n",
              "      <td>157</td>\n",
              "      <td>250</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   encounter_id  patient_nbr             race  ... change diabetesMed readmitted\n",
              "0       2278392      8222157        Caucasian  ...     No          No         NO\n",
              "1        149190     55629189        Caucasian  ...     Ch         Yes        >30\n",
              "2         64410     86047875  AfricanAmerican  ...     No         Yes         NO\n",
              "3        500364     82442376        Caucasian  ...     Ch         Yes         NO\n",
              "4         16680     42519267        Caucasian  ...     Ch         Yes         NO\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4YT5moDn-Ba",
        "outputId": "58c01613-bd2e-4648-a878-1281fd7aed7e"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgNsvyCSoLTP",
        "outputId": "b7eec427-fce2-46cc-d893-24c61dfde2d8"
      },
      "source": [
        "part1 = df[['diag_1']]\n",
        "part2 = df[['diag_2']]\n",
        "part3 = df[['diag_3']]\n",
        "part1.head()\n",
        "\n",
        "new_columns = ['diags']\n",
        "part1.columns = new_columns\n",
        "part2.columns = new_columns\n",
        "part3.columns = new_columns\n",
        "\n",
        "diags = pd.concat([part1, part2, part3], ignore_index=True)\n",
        "diags['diags'].nunique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p47fAgpoRdK",
        "outputId": "f87e6348-a870-4662-904b-e40979f4d72c"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encounter_id                 int64\n",
              "patient_nbr                  int64\n",
              "race                        object\n",
              "gender                      object\n",
              "age                         object\n",
              "weight                      object\n",
              "admission_type_id            int64\n",
              "discharge_disposition_id     int64\n",
              "admission_source_id          int64\n",
              "time_in_hospital             int64\n",
              "payer_code                  object\n",
              "medical_specialty           object\n",
              "num_lab_procedures           int64\n",
              "num_procedures               int64\n",
              "num_medications              int64\n",
              "number_outpatient            int64\n",
              "number_emergency             int64\n",
              "number_inpatient             int64\n",
              "diag_1                      object\n",
              "diag_2                      object\n",
              "diag_3                      object\n",
              "number_diagnoses             int64\n",
              "max_glu_serum               object\n",
              "A1Cresult                   object\n",
              "metformin                   object\n",
              "repaglinide                 object\n",
              "nateglinide                 object\n",
              "chlorpropamide              object\n",
              "glimepiride                 object\n",
              "acetohexamide               object\n",
              "glipizide                   object\n",
              "glyburide                   object\n",
              "tolbutamide                 object\n",
              "pioglitazone                object\n",
              "rosiglitazone               object\n",
              "acarbose                    object\n",
              "miglitol                    object\n",
              "troglitazone                object\n",
              "tolazamide                  object\n",
              "examide                     object\n",
              "citoglipton                 object\n",
              "insulin                     object\n",
              "glyburide-metformin         object\n",
              "glipizide-metformin         object\n",
              "glimepiride-pioglitazone    object\n",
              "metformin-rosiglitazone     object\n",
              "metformin-pioglitazone      object\n",
              "change                      object\n",
              "diabetesMed                 object\n",
              "readmitted                  object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iwJ-BOd5rlN"
      },
      "source": [
        "#remove records where patient has died\n",
        "df = df.loc[~df.discharge_disposition_id.isin([11,13,14,19,20,21])]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtE9r5VU6OF1"
      },
      "source": [
        "df['OUTPUT_LABEL'] = (df.readmitted == '<30').astype('int')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-VSxlq46UF9",
        "outputId": "8ce8bc5d-158a-4d37-e54d-c59a47f9464a"
      },
      "source": [
        "def calc_prevalence(y_actual):\n",
        "    return (sum(y_actual)/len(y_actual))\n",
        "\n",
        "print('Prevalence:%.3f'%calc_prevalence(df['OUTPUT_LABEL'].values))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prevalence:0.114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT7SUVG36cos",
        "outputId": "ffa699bd-71a0-4a56-cc56-9d793e6c8177"
      },
      "source": [
        "cols_num = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications',\n",
        "       'number_outpatient', 'number_emergency', 'number_inpatient','number_diagnoses']\n",
        "df[cols_num].isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time_in_hospital      0\n",
              "num_lab_procedures    0\n",
              "num_procedures        0\n",
              "num_medications       0\n",
              "number_outpatient     0\n",
              "number_emergency      0\n",
              "number_inpatient      0\n",
              "number_diagnoses      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upx0s9YY7OTq"
      },
      "source": [
        "cols_cat = ['race', 'gender', \n",
        "       'max_glu_serum', 'A1Cresult',\n",
        "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
        "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
        "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
        "       'tolazamide', 'insulin',\n",
        "       'glyburide-metformin', 'glipizide-metformin',\n",
        "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
        "       'metformin-pioglitazone', 'change', 'diabetesMed','payer_code']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBpuvYnC7aTa"
      },
      "source": [
        "df['race'] = df['race'].fillna('UNK')\n",
        "df['payer_code'] = df['payer_code'].fillna('UNK')\n",
        "df['medical_specialty'] = df['medical_specialty'].fillna('UNK')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASEzzkHP7jnK",
        "outputId": "a82f0e9b-f908-4343-e482-2787b1c9f132"
      },
      "source": [
        "print('Number medical specialty:', df.medical_specialty.nunique())\n",
        "df.groupby('medical_specialty').size().sort_values(ascending = False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number medical specialty: 73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "medical_specialty\n",
              "?                                48616\n",
              "InternalMedicine                 14237\n",
              "Emergency/Trauma                  7419\n",
              "Family/GeneralPractice            7252\n",
              "Cardiology                        5279\n",
              "                                 ...  \n",
              "Speech                               1\n",
              "Pediatrics-InfectiousDiseases        1\n",
              "SportsMedicine                       1\n",
              "Proctology                           1\n",
              "Neurophysiology                      1\n",
              "Length: 73, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eFCth6m7oSJ"
      },
      "source": [
        "top_10 = ['UNK','InternalMedicine','Emergency/Trauma',\\\n",
        "          'Family/GeneralPractice', 'Cardiology','Surgery-General' ,\\\n",
        "          'Nephrology','Orthopedics',\\\n",
        "          'Orthopedics-Reconstructive','Radiologist']\n",
        "\n",
        "# make a new column with duplicated data\n",
        "df['med_spec'] = df['medical_specialty'].copy()\n",
        "\n",
        "# replace all specialties not in top 10 with 'Other' category\n",
        "df.loc[~df.med_spec.isin(top_10),'med_spec'] = 'Other'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5lGfvQ_7rxp",
        "outputId": "e2003c1e-3e5b-4d58-f55f-97c140436c78"
      },
      "source": [
        "df.groupby('med_spec').size()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "med_spec\n",
              "Cardiology                     5279\n",
              "Emergency/Trauma               7419\n",
              "Family/GeneralPractice         7252\n",
              "InternalMedicine              14237\n",
              "Nephrology                     1539\n",
              "Orthopedics                    1392\n",
              "Orthopedics-Reconstructive     1230\n",
              "Other                         56815\n",
              "Radiologist                    1121\n",
              "Surgery-General                3059\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjc0F4cx7vmp"
      },
      "source": [
        "cols_cat_num = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
        "\n",
        "df[cols_cat_num] = df[cols_cat_num].astype('str')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "rG41zU9q70Lw",
        "outputId": "c5f2e287-fc7d-4234-d0a5-9c4f1d25a7e4"
      },
      "source": [
        "df_cat = pd.get_dummies(df[cols_cat + cols_cat_num + ['med_spec']],drop_first = True)\n",
        "df_cat.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race_AfricanAmerican</th>\n",
              "      <th>race_Asian</th>\n",
              "      <th>race_Caucasian</th>\n",
              "      <th>race_Hispanic</th>\n",
              "      <th>race_Other</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>gender_Unknown/Invalid</th>\n",
              "      <th>max_glu_serum_&gt;300</th>\n",
              "      <th>max_glu_serum_None</th>\n",
              "      <th>max_glu_serum_Norm</th>\n",
              "      <th>A1Cresult_&gt;8</th>\n",
              "      <th>A1Cresult_None</th>\n",
              "      <th>A1Cresult_Norm</th>\n",
              "      <th>metformin_No</th>\n",
              "      <th>metformin_Steady</th>\n",
              "      <th>metformin_Up</th>\n",
              "      <th>repaglinide_No</th>\n",
              "      <th>repaglinide_Steady</th>\n",
              "      <th>repaglinide_Up</th>\n",
              "      <th>nateglinide_No</th>\n",
              "      <th>nateglinide_Steady</th>\n",
              "      <th>nateglinide_Up</th>\n",
              "      <th>chlorpropamide_No</th>\n",
              "      <th>chlorpropamide_Steady</th>\n",
              "      <th>chlorpropamide_Up</th>\n",
              "      <th>glimepiride_No</th>\n",
              "      <th>glimepiride_Steady</th>\n",
              "      <th>glimepiride_Up</th>\n",
              "      <th>acetohexamide_Steady</th>\n",
              "      <th>glipizide_No</th>\n",
              "      <th>glipizide_Steady</th>\n",
              "      <th>glipizide_Up</th>\n",
              "      <th>glyburide_No</th>\n",
              "      <th>glyburide_Steady</th>\n",
              "      <th>glyburide_Up</th>\n",
              "      <th>tolbutamide_Steady</th>\n",
              "      <th>pioglitazone_No</th>\n",
              "      <th>pioglitazone_Steady</th>\n",
              "      <th>pioglitazone_Up</th>\n",
              "      <th>rosiglitazone_No</th>\n",
              "      <th>...</th>\n",
              "      <th>discharge_disposition_id_18</th>\n",
              "      <th>discharge_disposition_id_2</th>\n",
              "      <th>discharge_disposition_id_22</th>\n",
              "      <th>discharge_disposition_id_23</th>\n",
              "      <th>discharge_disposition_id_24</th>\n",
              "      <th>discharge_disposition_id_25</th>\n",
              "      <th>discharge_disposition_id_27</th>\n",
              "      <th>discharge_disposition_id_28</th>\n",
              "      <th>discharge_disposition_id_3</th>\n",
              "      <th>discharge_disposition_id_4</th>\n",
              "      <th>discharge_disposition_id_5</th>\n",
              "      <th>discharge_disposition_id_6</th>\n",
              "      <th>discharge_disposition_id_7</th>\n",
              "      <th>discharge_disposition_id_8</th>\n",
              "      <th>discharge_disposition_id_9</th>\n",
              "      <th>admission_source_id_10</th>\n",
              "      <th>admission_source_id_11</th>\n",
              "      <th>admission_source_id_13</th>\n",
              "      <th>admission_source_id_14</th>\n",
              "      <th>admission_source_id_17</th>\n",
              "      <th>admission_source_id_2</th>\n",
              "      <th>admission_source_id_20</th>\n",
              "      <th>admission_source_id_22</th>\n",
              "      <th>admission_source_id_25</th>\n",
              "      <th>admission_source_id_3</th>\n",
              "      <th>admission_source_id_4</th>\n",
              "      <th>admission_source_id_5</th>\n",
              "      <th>admission_source_id_6</th>\n",
              "      <th>admission_source_id_7</th>\n",
              "      <th>admission_source_id_8</th>\n",
              "      <th>admission_source_id_9</th>\n",
              "      <th>med_spec_Emergency/Trauma</th>\n",
              "      <th>med_spec_Family/GeneralPractice</th>\n",
              "      <th>med_spec_InternalMedicine</th>\n",
              "      <th>med_spec_Nephrology</th>\n",
              "      <th>med_spec_Orthopedics</th>\n",
              "      <th>med_spec_Orthopedics-Reconstructive</th>\n",
              "      <th>med_spec_Other</th>\n",
              "      <th>med_spec_Radiologist</th>\n",
              "      <th>med_spec_Surgery-General</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   race_AfricanAmerican  ...  med_spec_Surgery-General\n",
              "0                     0  ...                         0\n",
              "1                     0  ...                         0\n",
              "2                     1  ...                         0\n",
              "3                     0  ...                         0\n",
              "4                     0  ...                         0\n",
              "\n",
              "[5 rows x 132 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgiffKK38FEt"
      },
      "source": [
        "df = pd.concat([df,df_cat], axis = 1)\n",
        "cols_all_cat = list(df_cat.columns)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjwKDcBi8UAA",
        "outputId": "ffcdcaf0-6f92-48f1-b678-0140e97ee44d"
      },
      "source": [
        "df.groupby('age').size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age\n",
              "[0-10)        160\n",
              "[10-20)       690\n",
              "[20-30)      1649\n",
              "[30-40)      3764\n",
              "[40-50)      9607\n",
              "[50-60)     17060\n",
              "[60-70)     22059\n",
              "[70-80)     25331\n",
              "[80-90)     16434\n",
              "[90-100)     2589\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGsbMf0E8JTd"
      },
      "source": [
        "age_id = {'[0-10)':0, \n",
        "          '[10-20)':10, \n",
        "          '[20-30)':20, \n",
        "          '[30-40)':30, \n",
        "          '[40-50)':40, \n",
        "          '[50-60)':50,\n",
        "          '[60-70)':60, \n",
        "          '[70-80)':70, \n",
        "          '[80-90)':80, \n",
        "          '[90-100)':90}\n",
        "df['age_group'] = df.age.replace(age_id)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoDYiwOb8RnM"
      },
      "source": [
        "df['has_weight'] = df.weight.notnull().astype('int')\n",
        "cols_extra = ['age_group','has_weight']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CatpBNvT8m_B",
        "outputId": "3577974e-0b2b-4a4a-aa73-471c563645e0"
      },
      "source": [
        "print('Total number of features:', len(cols_num + cols_all_cat + cols_extra))\n",
        "print('Numerical Features:',len(cols_num))\n",
        "print('Categorical Features:',len(cols_all_cat))\n",
        "print('Extra features:',len(cols_extra))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of features: 142\n",
            "Numerical Features: 8\n",
            "Categorical Features: 132\n",
            "Extra features: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJyZNxmA8pk5"
      },
      "source": [
        "col2use = cols_num + cols_all_cat + cols_extra\n",
        "df_data = df[col2use + ['OUTPUT_LABEL']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I_qDZZu8-tf",
        "outputId": "6a9727f5-6ac6-4955-8922-0d3fc03b614c"
      },
      "source": [
        "# shuffle the samples\n",
        "df_data = df_data.sample(n = len(df_data), random_state = 42)\n",
        "df_data = df_data.reset_index(drop = True)\n",
        "df_valid_test=df_data.sample(frac=0.30,random_state=42)\n",
        "print('Split size: %.3f'%(len(df_valid_test)/len(df_data)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split size: 0.300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25_gvjxK90mX"
      },
      "source": [
        "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
        "df_valid = df_valid_test.drop(df_test.index)\n",
        "df_train_all=df_data.drop(df_valid_test.index)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgtbRZ4k98_G",
        "outputId": "75c615b6-5979-407f-efb7-ce42ccffabd5"
      },
      "source": [
        "print('Test prevalence(n = %d):%.3f'%(len(df_test),calc_prevalence(df_test.OUTPUT_LABEL.values)))\n",
        "print('Valid prevalence(n = %d):%.3f'%(len(df_valid),calc_prevalence(df_valid.OUTPUT_LABEL.values)))\n",
        "print('Train all prevalence(n = %d):%.3f'%(len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test prevalence(n = 14902):0.117\n",
            "Valid prevalence(n = 14901):0.113\n",
            "Train all prevalence(n = 69540):0.113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrFVd14E-CjV",
        "outputId": "b86f1246-7f35-4a85-cddf-d4aa84f1e2c6"
      },
      "source": [
        "# split the training data into positive and negative\n",
        "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
        "df_train_pos = df_train_all.loc[rows_pos]\n",
        "df_train_neg = df_train_all.loc[~rows_pos]\n",
        "\n",
        "# merge the balanced data\n",
        "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
        "\n",
        "# shuffle the order of training samples \n",
        "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
        "\n",
        "print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train balanced prevalence(n = 15766):0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ABE-Oa7-LH0"
      },
      "source": [
        "df_train_all.to_csv('df_train_all.csv',index=False)\n",
        "df_train.to_csv('df_train.csv',index=False)\n",
        "df_valid.to_csv('df_valid.csv',index=False)\n",
        "df_test.to_csv('df_test.csv',index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPxvJ58A-TNo",
        "outputId": "8ebb003c-5333-4438-fdac-915954fc716c"
      },
      "source": [
        "X_train = df_train[col2use].values\n",
        "X_train_all = df_train_all[col2use].values\n",
        "X_valid = df_valid[col2use].values\n",
        "\n",
        "y_train = df_train['OUTPUT_LABEL'].values\n",
        "y_valid = df_valid['OUTPUT_LABEL'].values\n",
        "\n",
        "print('Training All shapes:',X_train_all.shape)\n",
        "print('Training shapes:',X_train.shape, y_train.shape)\n",
        "print('Validation shapes:',X_valid.shape, y_valid.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training All shapes: (69540, 142)\n",
            "Training shapes: (15766, 142) (15766,)\n",
            "Validation shapes: (14901, 142) (14901,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IaFNDN_-YsQ",
        "outputId": "7026e9f9-6eec-4f2f-d7ed-9db020800ceb"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler  = StandardScaler()\n",
        "scaler.fit(X_train_all)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Us-zkh-eyd"
      },
      "source": [
        "import pickle\n",
        "scalerfile = 'scaler.sav'\n",
        "pickle.dump(scaler, open(scalerfile, 'wb'))\n",
        "scaler = pickle.load(open(scalerfile, 'rb'))\n",
        "X_train_tf = scaler.transform(X_train)\n",
        "X_valid_tf = scaler.transform(X_valid)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGpXIN_F-r7U"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "def calc_specificity(y_actual, y_pred, thresh):\n",
        "    # calculates specificity\n",
        "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
        "\n",
        "def print_report(y_actual, y_pred, thresh):\n",
        "    \n",
        "    auc = roc_auc_score(y_actual, y_pred)\n",
        "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
        "    recall = recall_score(y_actual, (y_pred > thresh))\n",
        "    precision = precision_score(y_actual, (y_pred > thresh))\n",
        "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
        "    print('AUC:%.3f'%auc)\n",
        "    print('accuracy:%.3f'%accuracy)\n",
        "    print('recall:%.3f'%recall)\n",
        "    print('precision:%.3f'%precision)\n",
        "    print('specificity:%.3f'%specificity)\n",
        "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
        "    print(' ')\n",
        "    return auc, accuracy, recall, precision, specificity"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3d9LDF-wvU"
      },
      "source": [
        "thresh = 0.5"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdD_BoWo-3_t",
        "outputId": "5a8eb259-aa7d-41cd-cfcc-a4a2066a2c59"
      },
      "source": [
        "# k-nearest neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors = 100)\n",
        "knn.fit(X_train_tf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-DQYhik-7fT",
        "outputId": "ea11b944-9366-402a-9b91-f78f0bafef9e"
      },
      "source": [
        "y_train_preds = knn.predict_proba(X_train_tf)[:,1]\n",
        "y_valid_preds = knn.predict_proba(X_valid_tf)[:,1]\n",
        "\n",
        "print('KNN')\n",
        "print('Training:')\n",
        "knn_train_auc, knn_train_accuracy, knn_train_recall, \\\n",
        "    knn_train_precision, knn_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
        "print('Validation:')\n",
        "knn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\n",
        "    knn_valid_precision, knn_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "Training:\n",
            "AUC:0.652\n",
            "accuracy:0.606\n",
            "recall:0.498\n",
            "precision:0.636\n",
            "specificity:0.676\n",
            "prevalence:0.500\n",
            " \n",
            "Validation:\n",
            "AUC:0.619\n",
            "accuracy:0.667\n",
            "recall:0.469\n",
            "precision:0.163\n",
            "specificity:0.648\n",
            "prevalence:0.113\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p20g05U6-87L",
        "outputId": "596088ca-76cf-4da8-c607-9385ba3ff9fc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf=RandomForestClassifier(max_depth = 6, random_state = 42)\n",
        "rf.fit(X_train_tf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=6, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMEGqAuJ_TqP",
        "outputId": "c2f5141a-bfe8-4dc0-e091-90ed30716012"
      },
      "source": [
        "y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
        "y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
        "\n",
        "print('Random Forest')\n",
        "print('Training:')\n",
        "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
        "print('Validation:')\n",
        "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "Training:\n",
            "AUC:0.693\n",
            "accuracy:0.640\n",
            "recall:0.603\n",
            "precision:0.651\n",
            "specificity:0.677\n",
            "prevalence:0.500\n",
            " \n",
            "Validation:\n",
            "AUC:0.654\n",
            "accuracy:0.631\n",
            "recall:0.586\n",
            "precision:0.171\n",
            "specificity:0.637\n",
            "prevalence:0.113\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBUvcSeS_d21",
        "outputId": "a01cc58a-8eba-4c8a-95bb-b1102f4b82ef"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbc =GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "     max_depth=3, random_state=42)\n",
        "gbc.fit(X_train_tf, y_train)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=1.0, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=42, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4IUemzV_enP",
        "outputId": "0345f978-046f-4e32-e0cd-846fdfed930b"
      },
      "source": [
        "y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
        "y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
        "\n",
        "print('Gradient Boosting Classifier')\n",
        "print('Training:')\n",
        "gbc_train_auc, gbc_train_accuracy, gbc_train_recall, gbc_train_precision, gbc_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
        "print('Validation:')\n",
        "gbc_valid_auc, gbc_valid_accuracy, gbc_valid_recall, gbc_valid_precision, gbc_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Boosting Classifier\n",
            "Training:\n",
            "AUC:0.774\n",
            "accuracy:0.700\n",
            "recall:0.671\n",
            "precision:0.712\n",
            "specificity:0.729\n",
            "prevalence:0.500\n",
            " \n",
            "Validation:\n",
            "AUC:0.635\n",
            "accuracy:0.623\n",
            "recall:0.574\n",
            "precision:0.165\n",
            "specificity:0.629\n",
            "prevalence:0.113\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxB9GUOsBEjb",
        "outputId": "a644ee35-97b3-4e48-dda1-9cadfb68e85b"
      },
      "source": [
        "#Lets try make use of the diagnosis codes - we will treat them as NLP, and use a LSTM model so the order of the diagnosis is taken into account\n",
        "#first combine the three diagnosis codes\n",
        "import texthero as hero\n",
        "from texthero import preprocessing\n",
        "\n",
        "df['lstm'] = df[['diag_1', 'diag_2', 'diag_3']].agg(' '.join, axis=1)\n",
        "df_lstm = df[['lstm'] + col2use + ['OUTPUT_LABEL']]\n",
        "\n",
        "word_features=56\n",
        "df_lstm['tfidf'] = (hero.tfidf(df_lstm['lstm'], max_features=word_features))\n",
        "print(df_lstm[['tfidf']])\n",
        "# shuffle the samples\n",
        "df_lstm = df_lstm.sample(n = len(df_lstm), random_state = 42)\n",
        "df_lstm = df_lstm.reset_index(drop = True)\n",
        "df_lstm_valid_test=df_lstm.sample(frac=0.30,random_state=42)\n",
        "print('Split size: %.3f'%(len(df_lstm_valid_test)/len(df_lstm)))\n",
        "df_lstm_test = df_lstm_valid_test.sample(frac = 0.5, random_state = 42)\n",
        "df_lstm_valid = df_lstm_valid_test.drop(df_lstm_test.index)\n",
        "df_train_all=df_lstm.drop(df_lstm_valid_test.index)\n",
        "\n",
        "# split the training data into positive and negative\n",
        "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
        "df_train_pos = df_train_all.loc[rows_pos]\n",
        "df_train_neg = df_train_all.loc[~rows_pos]\n",
        "\n",
        "# merge the balanced data\n",
        "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
        "\n",
        "# shuffle the order of training samples \n",
        "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
        "\n",
        "print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                    tfidf\n",
            "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "1       [0.0, 0.8369328371372543, 0.0, 0.0, 0.0, 0.0, ...\n",
            "2       [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "4       [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "...                                                   ...\n",
            "101761  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "101762  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.50850225...\n",
            "101763  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "101764  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "101765  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
            "\n",
            "[99343 rows x 1 columns]\n",
            "Split size: 0.300\n",
            "Train balanced prevalence(n = 15766):0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QHIkvR1yNkrl",
        "outputId": "62d330f7-ddcb-4910-d55e-a74add7618c7"
      },
      "source": [
        "df_train_all.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lstm</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>race_AfricanAmerican</th>\n",
              "      <th>race_Asian</th>\n",
              "      <th>race_Caucasian</th>\n",
              "      <th>race_Hispanic</th>\n",
              "      <th>race_Other</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>gender_Unknown/Invalid</th>\n",
              "      <th>max_glu_serum_&gt;300</th>\n",
              "      <th>max_glu_serum_None</th>\n",
              "      <th>max_glu_serum_Norm</th>\n",
              "      <th>A1Cresult_&gt;8</th>\n",
              "      <th>A1Cresult_None</th>\n",
              "      <th>A1Cresult_Norm</th>\n",
              "      <th>metformin_No</th>\n",
              "      <th>metformin_Steady</th>\n",
              "      <th>metformin_Up</th>\n",
              "      <th>repaglinide_No</th>\n",
              "      <th>repaglinide_Steady</th>\n",
              "      <th>repaglinide_Up</th>\n",
              "      <th>nateglinide_No</th>\n",
              "      <th>nateglinide_Steady</th>\n",
              "      <th>nateglinide_Up</th>\n",
              "      <th>chlorpropamide_No</th>\n",
              "      <th>chlorpropamide_Steady</th>\n",
              "      <th>chlorpropamide_Up</th>\n",
              "      <th>glimepiride_No</th>\n",
              "      <th>glimepiride_Steady</th>\n",
              "      <th>glimepiride_Up</th>\n",
              "      <th>acetohexamide_Steady</th>\n",
              "      <th>glipizide_No</th>\n",
              "      <th>glipizide_Steady</th>\n",
              "      <th>...</th>\n",
              "      <th>discharge_disposition_id_24</th>\n",
              "      <th>discharge_disposition_id_25</th>\n",
              "      <th>discharge_disposition_id_27</th>\n",
              "      <th>discharge_disposition_id_28</th>\n",
              "      <th>discharge_disposition_id_3</th>\n",
              "      <th>discharge_disposition_id_4</th>\n",
              "      <th>discharge_disposition_id_5</th>\n",
              "      <th>discharge_disposition_id_6</th>\n",
              "      <th>discharge_disposition_id_7</th>\n",
              "      <th>discharge_disposition_id_8</th>\n",
              "      <th>discharge_disposition_id_9</th>\n",
              "      <th>admission_source_id_10</th>\n",
              "      <th>admission_source_id_11</th>\n",
              "      <th>admission_source_id_13</th>\n",
              "      <th>admission_source_id_14</th>\n",
              "      <th>admission_source_id_17</th>\n",
              "      <th>admission_source_id_2</th>\n",
              "      <th>admission_source_id_20</th>\n",
              "      <th>admission_source_id_22</th>\n",
              "      <th>admission_source_id_25</th>\n",
              "      <th>admission_source_id_3</th>\n",
              "      <th>admission_source_id_4</th>\n",
              "      <th>admission_source_id_5</th>\n",
              "      <th>admission_source_id_6</th>\n",
              "      <th>admission_source_id_7</th>\n",
              "      <th>admission_source_id_8</th>\n",
              "      <th>admission_source_id_9</th>\n",
              "      <th>med_spec_Emergency/Trauma</th>\n",
              "      <th>med_spec_Family/GeneralPractice</th>\n",
              "      <th>med_spec_InternalMedicine</th>\n",
              "      <th>med_spec_Nephrology</th>\n",
              "      <th>med_spec_Orthopedics</th>\n",
              "      <th>med_spec_Orthopedics-Reconstructive</th>\n",
              "      <th>med_spec_Other</th>\n",
              "      <th>med_spec_Radiologist</th>\n",
              "      <th>med_spec_Surgery-General</th>\n",
              "      <th>age_group</th>\n",
              "      <th>has_weight</th>\n",
              "      <th>OUTPUT_LABEL</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>410 428 496</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>493 250.02 278</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.5110256306484189, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>577 276 574</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38136073...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>998 682 250.02</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.5347375189465576, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>38 428 427</td>\n",
              "      <td>9</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 145 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             lstm  ...                                              tfidf\n",
              "0     410 428 496  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "1  493 250.02 278  ...  [0.0, 0.0, 0.5110256306484189, 0.0, 0.0, 0.0, ...\n",
              "2     577 276 574  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38136073...\n",
              "3  998 682 250.02  ...  [0.0, 0.0, 0.5347375189465576, 0.0, 0.0, 0.0, ...\n",
              "4      38 428 427  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "\n",
              "[5 rows x 145 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_rk6rcVIvmu"
      },
      "source": [
        "#Convert data to numpy arrays for keras/tensorflow\n",
        "\n",
        "X_train = np.array(df_train.tfidf.tolist())\n",
        "X_train_con = df_train[col2use].to_numpy()\n",
        "y_train = np.array(df_train.OUTPUT_LABEL.tolist())\n",
        "X_test  = np.array(df_lstm_test.tfidf.tolist())\n",
        "X_test_con  = df_lstm_test[col2use].to_numpy()\n",
        "y_test  = np.array(df_lstm_test.OUTPUT_LABEL.tolist())\n",
        "X_valid  = np.array(df_lstm_valid.tfidf.tolist())\n",
        "X_valid_con  = df_lstm_valid[col2use].to_numpy()\n",
        "y_valid  = np.array(df_lstm_valid.OUTPUT_LABEL.tolist())\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kt16bgKK37M",
        "outputId": "8d1fc138-21cd-454d-e585-e32f8f39871f"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "#input of our vector of diagnosis codes\n",
        "input = Input(shape=(word_features,), dtype='int32')\n",
        "#Create and embedding layer from the input\n",
        "embed = Embedding(input_dim=word_features, output_dim=12)(input)\n",
        "#Add LSTM lay to allow diagnosis codes order to be reflected\n",
        "lstm = LSTM(3, dropout=0.1, recurrent_dropout=0.1)(embed)\n",
        "#Add all other features\n",
        "agei = Input(shape=(142,))\n",
        "conc = concatenate([lstm, agei])\n",
        "drop = Dropout(0.1)(conc)\n",
        "#Add some hidden layers with dropout as the model is overfitting\n",
        "hidden = Dense(128, activation='relu')(drop)\n",
        "drop1 = Dropout(0.1)(hidden)\n",
        "hidden2 = Dense(128, activation='relu')(drop1)\n",
        "drop2 = Dropout(0.05)(hidden2)\n",
        "hidden3 = Dense(32, activation='relu')(drop2)\n",
        "dens = Dense(1)(hidden3)\n",
        "#Add layer with single output with sigmoid activation for a binary prediction\n",
        "acti = Activation('sigmoid')(dens)\n",
        "model = Model(inputs=[input, agei], outputs=acti)\n",
        "print(model.summary())\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit([X_train, X_train_con], y_train, validation_data=([X_test,X_test_con] , y_test), epochs=300, batch_size=1000)\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_58\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_54 (InputLayer)           [(None, 56)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_24 (Embedding)        (None, 56, 12)       672         input_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_24 (LSTM)                  (None, 3)            192         embedding_24[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_55 (InputLayer)           [(None, 142)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 145)          0           lstm_24[0][0]                    \n",
            "                                                                 input_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 145)          0           concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_106 (Dense)               (None, 128)          18688       dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 128)          0           dense_106[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_107 (Dense)               (None, 128)          16512       dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 128)          0           dense_107[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_108 (Dense)               (None, 32)           4128        dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_109 (Dense)               (None, 1)            33          dense_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 1)            0           dense_109[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 40,225\n",
            "Trainable params: 40,225\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/300\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.9675 - accuracy: 0.5010 - val_loss: 0.5521 - val_accuracy: 0.8609\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.7525 - accuracy: 0.5069 - val_loss: 0.7459 - val_accuracy: 0.3055\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.7192 - accuracy: 0.5213 - val_loss: 0.7353 - val_accuracy: 0.3359\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.7075 - accuracy: 0.5253 - val_loss: 0.7524 - val_accuracy: 0.2697\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.7016 - accuracy: 0.5298 - val_loss: 0.7594 - val_accuracy: 0.2514\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6944 - accuracy: 0.5362 - val_loss: 0.7140 - val_accuracy: 0.4366\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6916 - accuracy: 0.5440 - val_loss: 0.7016 - val_accuracy: 0.4955\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6892 - accuracy: 0.5436 - val_loss: 0.6771 - val_accuracy: 0.6214\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6872 - accuracy: 0.5507 - val_loss: 0.7073 - val_accuracy: 0.5041\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6798 - accuracy: 0.5704 - val_loss: 0.7268 - val_accuracy: 0.4409\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6787 - accuracy: 0.5651 - val_loss: 0.6931 - val_accuracy: 0.5582\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6796 - accuracy: 0.5696 - val_loss: 0.7267 - val_accuracy: 0.4655\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6746 - accuracy: 0.5767 - val_loss: 0.7106 - val_accuracy: 0.5291\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6756 - accuracy: 0.5790 - val_loss: 0.6710 - val_accuracy: 0.6369\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6749 - accuracy: 0.5806 - val_loss: 0.7220 - val_accuracy: 0.5133\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6730 - accuracy: 0.5811 - val_loss: 0.7478 - val_accuracy: 0.4419\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6718 - accuracy: 0.5866 - val_loss: 0.6493 - val_accuracy: 0.6886\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6713 - accuracy: 0.5800 - val_loss: 0.7067 - val_accuracy: 0.5534\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6672 - accuracy: 0.5952 - val_loss: 0.7111 - val_accuracy: 0.5531\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6677 - accuracy: 0.5939 - val_loss: 0.6815 - val_accuracy: 0.6131\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6660 - accuracy: 0.5925 - val_loss: 0.6719 - val_accuracy: 0.6347\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6683 - accuracy: 0.5914 - val_loss: 0.7110 - val_accuracy: 0.5410\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6649 - accuracy: 0.5945 - val_loss: 0.6792 - val_accuracy: 0.5994\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6658 - accuracy: 0.5966 - val_loss: 0.6311 - val_accuracy: 0.6841\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6651 - accuracy: 0.5958 - val_loss: 0.6535 - val_accuracy: 0.6540\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6654 - accuracy: 0.5934 - val_loss: 0.6921 - val_accuracy: 0.5740\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6643 - accuracy: 0.5972 - val_loss: 0.6264 - val_accuracy: 0.6769\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6611 - accuracy: 0.6041 - val_loss: 0.6342 - val_accuracy: 0.6676\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6621 - accuracy: 0.5992 - val_loss: 0.6877 - val_accuracy: 0.5712\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6586 - accuracy: 0.6052 - val_loss: 0.6624 - val_accuracy: 0.6207\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6618 - accuracy: 0.6018 - val_loss: 0.7049 - val_accuracy: 0.5365\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6595 - accuracy: 0.6054 - val_loss: 0.6575 - val_accuracy: 0.6257\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6586 - accuracy: 0.6050 - val_loss: 0.7260 - val_accuracy: 0.4966\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6580 - accuracy: 0.6113 - val_loss: 0.6438 - val_accuracy: 0.6390\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6591 - accuracy: 0.6059 - val_loss: 0.7447 - val_accuracy: 0.4369\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6605 - accuracy: 0.6067 - val_loss: 0.7184 - val_accuracy: 0.4982\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6581 - accuracy: 0.6091 - val_loss: 0.6420 - val_accuracy: 0.6359\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6590 - accuracy: 0.6067 - val_loss: 0.6663 - val_accuracy: 0.6000\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6559 - accuracy: 0.6116 - val_loss: 0.6845 - val_accuracy: 0.5652\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6566 - accuracy: 0.6085 - val_loss: 0.6740 - val_accuracy: 0.5841\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6565 - accuracy: 0.6131 - val_loss: 0.6637 - val_accuracy: 0.6022\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6558 - accuracy: 0.6087 - val_loss: 0.6318 - val_accuracy: 0.6440\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6569 - accuracy: 0.6111 - val_loss: 0.6635 - val_accuracy: 0.5973\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6570 - accuracy: 0.6087 - val_loss: 0.6066 - val_accuracy: 0.6804\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6581 - accuracy: 0.6048 - val_loss: 0.6575 - val_accuracy: 0.6106\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6550 - accuracy: 0.6147 - val_loss: 0.6658 - val_accuracy: 0.5943\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6550 - accuracy: 0.6172 - val_loss: 0.6377 - val_accuracy: 0.6324\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6563 - accuracy: 0.6085 - val_loss: 0.6358 - val_accuracy: 0.6582\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6542 - accuracy: 0.6134 - val_loss: 0.6505 - val_accuracy: 0.6137\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6564 - accuracy: 0.6093 - val_loss: 0.6890 - val_accuracy: 0.5568\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6555 - accuracy: 0.6107 - val_loss: 0.6578 - val_accuracy: 0.6032\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6557 - accuracy: 0.6145 - val_loss: 0.6570 - val_accuracy: 0.6028\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.6539 - accuracy: 0.6130 - val_loss: 0.6624 - val_accuracy: 0.5995\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6534 - accuracy: 0.6154 - val_loss: 0.6979 - val_accuracy: 0.5419\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6545 - accuracy: 0.6133 - val_loss: 0.6178 - val_accuracy: 0.6698\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6551 - accuracy: 0.6106 - val_loss: 0.6505 - val_accuracy: 0.6303\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6516 - accuracy: 0.6163 - val_loss: 0.6976 - val_accuracy: 0.5515\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6530 - accuracy: 0.6170 - val_loss: 0.6293 - val_accuracy: 0.6437\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6514 - accuracy: 0.6177 - val_loss: 0.6695 - val_accuracy: 0.5886\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6542 - accuracy: 0.6141 - val_loss: 0.6606 - val_accuracy: 0.6066\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6519 - accuracy: 0.6202 - val_loss: 0.6621 - val_accuracy: 0.5939\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6514 - accuracy: 0.6136 - val_loss: 0.6533 - val_accuracy: 0.6098\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6521 - accuracy: 0.6154 - val_loss: 0.6560 - val_accuracy: 0.6107\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6520 - accuracy: 0.6190 - val_loss: 0.6364 - val_accuracy: 0.6346\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6497 - accuracy: 0.6181 - val_loss: 0.6254 - val_accuracy: 0.6549\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6508 - accuracy: 0.6188 - val_loss: 0.6435 - val_accuracy: 0.6300\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6515 - accuracy: 0.6125 - val_loss: 0.6830 - val_accuracy: 0.5625\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6512 - accuracy: 0.6163 - val_loss: 0.6229 - val_accuracy: 0.6495\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6523 - accuracy: 0.6123 - val_loss: 0.7262 - val_accuracy: 0.4905\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6525 - accuracy: 0.6121 - val_loss: 0.6757 - val_accuracy: 0.5748\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6506 - accuracy: 0.6167 - val_loss: 0.6268 - val_accuracy: 0.6633\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6507 - accuracy: 0.6177 - val_loss: 0.6502 - val_accuracy: 0.6229\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6503 - accuracy: 0.6184 - val_loss: 0.6350 - val_accuracy: 0.6450\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6499 - accuracy: 0.6218 - val_loss: 0.6838 - val_accuracy: 0.5639\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6506 - accuracy: 0.6172 - val_loss: 0.6340 - val_accuracy: 0.6590\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6502 - accuracy: 0.6166 - val_loss: 0.6706 - val_accuracy: 0.5882\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6513 - accuracy: 0.6164 - val_loss: 0.6685 - val_accuracy: 0.5918\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6501 - accuracy: 0.6146 - val_loss: 0.6031 - val_accuracy: 0.6919\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6508 - accuracy: 0.6134 - val_loss: 0.6443 - val_accuracy: 0.6314\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6500 - accuracy: 0.6163 - val_loss: 0.7009 - val_accuracy: 0.5362\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.6494 - accuracy: 0.6208 - val_loss: 0.6947 - val_accuracy: 0.5468\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6501 - accuracy: 0.6133 - val_loss: 0.6289 - val_accuracy: 0.6423\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6478 - accuracy: 0.6220 - val_loss: 0.6562 - val_accuracy: 0.6038\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6499 - accuracy: 0.6172 - val_loss: 0.6725 - val_accuracy: 0.5800\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6471 - accuracy: 0.6192 - val_loss: 0.6328 - val_accuracy: 0.6444\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6469 - accuracy: 0.6213 - val_loss: 0.6581 - val_accuracy: 0.6034\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 2s 153ms/step - loss: 0.6484 - accuracy: 0.6170 - val_loss: 0.6648 - val_accuracy: 0.5911\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6487 - accuracy: 0.6198 - val_loss: 0.6610 - val_accuracy: 0.6068\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6498 - accuracy: 0.6165 - val_loss: 0.6495 - val_accuracy: 0.6190\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6446 - accuracy: 0.6277 - val_loss: 0.6739 - val_accuracy: 0.5859\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6482 - accuracy: 0.6246 - val_loss: 0.6424 - val_accuracy: 0.6401\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6470 - accuracy: 0.6220 - val_loss: 0.6075 - val_accuracy: 0.6729\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6474 - accuracy: 0.6218 - val_loss: 0.6532 - val_accuracy: 0.6193\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6466 - accuracy: 0.6227 - val_loss: 0.6495 - val_accuracy: 0.6204\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6460 - accuracy: 0.6214 - val_loss: 0.6464 - val_accuracy: 0.6234\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6468 - accuracy: 0.6203 - val_loss: 0.6512 - val_accuracy: 0.6307\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6448 - accuracy: 0.6253 - val_loss: 0.6310 - val_accuracy: 0.6499\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6452 - accuracy: 0.6237 - val_loss: 0.6660 - val_accuracy: 0.5985\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6468 - accuracy: 0.6178 - val_loss: 0.6512 - val_accuracy: 0.6205\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6451 - accuracy: 0.6224 - val_loss: 0.6512 - val_accuracy: 0.6121\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6464 - accuracy: 0.6215 - val_loss: 0.6133 - val_accuracy: 0.6788\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6484 - accuracy: 0.6191 - val_loss: 0.6363 - val_accuracy: 0.6366\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6461 - accuracy: 0.6187 - val_loss: 0.7640 - val_accuracy: 0.4424\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6499 - accuracy: 0.6165 - val_loss: 0.6368 - val_accuracy: 0.6462\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6477 - accuracy: 0.6200 - val_loss: 0.6604 - val_accuracy: 0.6080\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6463 - accuracy: 0.6213 - val_loss: 0.6838 - val_accuracy: 0.5747\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6457 - accuracy: 0.6203 - val_loss: 0.6953 - val_accuracy: 0.5458\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6469 - accuracy: 0.6193 - val_loss: 0.6492 - val_accuracy: 0.6194\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6448 - accuracy: 0.6239 - val_loss: 0.6282 - val_accuracy: 0.6584\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6450 - accuracy: 0.6232 - val_loss: 0.6394 - val_accuracy: 0.6372\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6455 - accuracy: 0.6265 - val_loss: 0.6315 - val_accuracy: 0.6553\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6453 - accuracy: 0.6212 - val_loss: 0.6309 - val_accuracy: 0.6552\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6446 - accuracy: 0.6209 - val_loss: 0.7114 - val_accuracy: 0.5216\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6451 - accuracy: 0.6208 - val_loss: 0.6645 - val_accuracy: 0.6003\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6454 - accuracy: 0.6230 - val_loss: 0.6500 - val_accuracy: 0.6256\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6431 - accuracy: 0.6229 - val_loss: 0.6723 - val_accuracy: 0.5934\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6445 - accuracy: 0.6234 - val_loss: 0.6667 - val_accuracy: 0.5992\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6437 - accuracy: 0.6271 - val_loss: 0.6214 - val_accuracy: 0.6576\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6426 - accuracy: 0.6258 - val_loss: 0.6467 - val_accuracy: 0.6241\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6430 - accuracy: 0.6300 - val_loss: 0.6870 - val_accuracy: 0.5662\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6441 - accuracy: 0.6253 - val_loss: 0.6335 - val_accuracy: 0.6502\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6423 - accuracy: 0.6290 - val_loss: 0.6353 - val_accuracy: 0.6300\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6436 - accuracy: 0.6262 - val_loss: 0.6351 - val_accuracy: 0.6362\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6432 - accuracy: 0.6270 - val_loss: 0.6928 - val_accuracy: 0.5631\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6440 - accuracy: 0.6244 - val_loss: 0.6589 - val_accuracy: 0.6215\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6425 - accuracy: 0.6275 - val_loss: 0.6282 - val_accuracy: 0.6558\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6427 - accuracy: 0.6254 - val_loss: 0.6655 - val_accuracy: 0.5954\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6433 - accuracy: 0.6281 - val_loss: 0.6341 - val_accuracy: 0.6376\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6405 - accuracy: 0.6269 - val_loss: 0.6532 - val_accuracy: 0.6073\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6416 - accuracy: 0.6277 - val_loss: 0.6515 - val_accuracy: 0.6227\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6401 - accuracy: 0.6321 - val_loss: 0.6593 - val_accuracy: 0.6093\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6397 - accuracy: 0.6296 - val_loss: 0.6363 - val_accuracy: 0.6494\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6414 - accuracy: 0.6268 - val_loss: 0.7045 - val_accuracy: 0.5392\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.6428 - accuracy: 0.6242 - val_loss: 0.6698 - val_accuracy: 0.5790\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6421 - accuracy: 0.6263 - val_loss: 0.6269 - val_accuracy: 0.6566\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6407 - accuracy: 0.6286 - val_loss: 0.6286 - val_accuracy: 0.6385\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6419 - accuracy: 0.6278 - val_loss: 0.6271 - val_accuracy: 0.6530\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6426 - accuracy: 0.6236 - val_loss: 0.6866 - val_accuracy: 0.5717\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6403 - accuracy: 0.6272 - val_loss: 0.6553 - val_accuracy: 0.6182\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6407 - accuracy: 0.6269 - val_loss: 0.6590 - val_accuracy: 0.6197\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6402 - accuracy: 0.6234 - val_loss: 0.6313 - val_accuracy: 0.6441\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6407 - accuracy: 0.6277 - val_loss: 0.6575 - val_accuracy: 0.6137\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6379 - accuracy: 0.6310 - val_loss: 0.6323 - val_accuracy: 0.6564\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6391 - accuracy: 0.6281 - val_loss: 0.6166 - val_accuracy: 0.6601\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6405 - accuracy: 0.6302 - val_loss: 0.6500 - val_accuracy: 0.6243\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6384 - accuracy: 0.6318 - val_loss: 0.6639 - val_accuracy: 0.5952\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6403 - accuracy: 0.6301 - val_loss: 0.5958 - val_accuracy: 0.6941\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6427 - accuracy: 0.6213 - val_loss: 0.6675 - val_accuracy: 0.5926\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6407 - accuracy: 0.6316 - val_loss: 0.6424 - val_accuracy: 0.6331\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6377 - accuracy: 0.6311 - val_loss: 0.6497 - val_accuracy: 0.6265\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 2s 151ms/step - loss: 0.6388 - accuracy: 0.6307 - val_loss: 0.6501 - val_accuracy: 0.6309\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.6401 - accuracy: 0.6281 - val_loss: 0.6301 - val_accuracy: 0.6447\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.6389 - accuracy: 0.6282 - val_loss: 0.6229 - val_accuracy: 0.6621\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6375 - accuracy: 0.6315 - val_loss: 0.6763 - val_accuracy: 0.5791\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6379 - accuracy: 0.6303 - val_loss: 0.6245 - val_accuracy: 0.6581\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6399 - accuracy: 0.6307 - val_loss: 0.6562 - val_accuracy: 0.6221\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6367 - accuracy: 0.6306 - val_loss: 0.6733 - val_accuracy: 0.5915\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6373 - accuracy: 0.6346 - val_loss: 0.6168 - val_accuracy: 0.6618\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6379 - accuracy: 0.6323 - val_loss: 0.6764 - val_accuracy: 0.5801\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6364 - accuracy: 0.6315 - val_loss: 0.6369 - val_accuracy: 0.6337\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6350 - accuracy: 0.6333 - val_loss: 0.6558 - val_accuracy: 0.6270\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6373 - accuracy: 0.6315 - val_loss: 0.6434 - val_accuracy: 0.6298\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6380 - accuracy: 0.6272 - val_loss: 0.6400 - val_accuracy: 0.6388\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6359 - accuracy: 0.6331 - val_loss: 0.6380 - val_accuracy: 0.6481\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6332 - accuracy: 0.6355 - val_loss: 0.6410 - val_accuracy: 0.6258\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6353 - accuracy: 0.6341 - val_loss: 0.6615 - val_accuracy: 0.6094\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6333 - accuracy: 0.6356 - val_loss: 0.6128 - val_accuracy: 0.6713\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6323 - accuracy: 0.6365 - val_loss: 0.6611 - val_accuracy: 0.6147\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6342 - accuracy: 0.6348 - val_loss: 0.6308 - val_accuracy: 0.6554\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6345 - accuracy: 0.6353 - val_loss: 0.6694 - val_accuracy: 0.5913\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6345 - accuracy: 0.6307 - val_loss: 0.6655 - val_accuracy: 0.6154\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6323 - accuracy: 0.6371 - val_loss: 0.6360 - val_accuracy: 0.6407\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6335 - accuracy: 0.6329 - val_loss: 0.6623 - val_accuracy: 0.6174\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6334 - accuracy: 0.6336 - val_loss: 0.6339 - val_accuracy: 0.6390\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6322 - accuracy: 0.6351 - val_loss: 0.6393 - val_accuracy: 0.6449\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6343 - accuracy: 0.6329 - val_loss: 0.6243 - val_accuracy: 0.6609\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6323 - accuracy: 0.6333 - val_loss: 0.6683 - val_accuracy: 0.5960\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6344 - accuracy: 0.6341 - val_loss: 0.6512 - val_accuracy: 0.6235\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6297 - accuracy: 0.6366 - val_loss: 0.6551 - val_accuracy: 0.6319\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6322 - accuracy: 0.6335 - val_loss: 0.6694 - val_accuracy: 0.6107\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6326 - accuracy: 0.6351 - val_loss: 0.6441 - val_accuracy: 0.6367\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6326 - accuracy: 0.6348 - val_loss: 0.6878 - val_accuracy: 0.5770\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6351 - accuracy: 0.6335 - val_loss: 0.6639 - val_accuracy: 0.6033\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6302 - accuracy: 0.6405 - val_loss: 0.6675 - val_accuracy: 0.6170\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6328 - accuracy: 0.6309 - val_loss: 0.6439 - val_accuracy: 0.6337\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6314 - accuracy: 0.6367 - val_loss: 0.6100 - val_accuracy: 0.6786\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6286 - accuracy: 0.6382 - val_loss: 0.6849 - val_accuracy: 0.5719\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6301 - accuracy: 0.6394 - val_loss: 0.6779 - val_accuracy: 0.6031\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6300 - accuracy: 0.6367 - val_loss: 0.7021 - val_accuracy: 0.5430\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6308 - accuracy: 0.6344 - val_loss: 0.6086 - val_accuracy: 0.6846\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6303 - accuracy: 0.6352 - val_loss: 0.6643 - val_accuracy: 0.6142\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6280 - accuracy: 0.6354 - val_loss: 0.6926 - val_accuracy: 0.5750\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6305 - accuracy: 0.6343 - val_loss: 0.6634 - val_accuracy: 0.5993\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6284 - accuracy: 0.6410 - val_loss: 0.6211 - val_accuracy: 0.6509\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6267 - accuracy: 0.6413 - val_loss: 0.7015 - val_accuracy: 0.5750\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6288 - accuracy: 0.6369 - val_loss: 0.6769 - val_accuracy: 0.5905\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6291 - accuracy: 0.6397 - val_loss: 0.6421 - val_accuracy: 0.6374\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6237 - accuracy: 0.6490 - val_loss: 0.6537 - val_accuracy: 0.6165\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6285 - accuracy: 0.6398 - val_loss: 0.6750 - val_accuracy: 0.6117\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6267 - accuracy: 0.6381 - val_loss: 0.6903 - val_accuracy: 0.5822\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6280 - accuracy: 0.6381 - val_loss: 0.6598 - val_accuracy: 0.6163\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.6261 - accuracy: 0.6424 - val_loss: 0.6144 - val_accuracy: 0.6770\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6275 - accuracy: 0.6410 - val_loss: 0.6697 - val_accuracy: 0.6116\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6264 - accuracy: 0.6404 - val_loss: 0.6536 - val_accuracy: 0.6343\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6237 - accuracy: 0.6440 - val_loss: 0.6700 - val_accuracy: 0.6047\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6242 - accuracy: 0.6432 - val_loss: 0.6567 - val_accuracy: 0.6267\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6253 - accuracy: 0.6400 - val_loss: 0.6575 - val_accuracy: 0.6137\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6212 - accuracy: 0.6481 - val_loss: 0.6674 - val_accuracy: 0.6202\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6250 - accuracy: 0.6409 - val_loss: 0.6655 - val_accuracy: 0.6149\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6231 - accuracy: 0.6478 - val_loss: 0.6429 - val_accuracy: 0.6411\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6231 - accuracy: 0.6491 - val_loss: 0.6671 - val_accuracy: 0.6033\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6257 - accuracy: 0.6414 - val_loss: 0.6781 - val_accuracy: 0.6119\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6234 - accuracy: 0.6468 - val_loss: 0.6701 - val_accuracy: 0.5944\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6195 - accuracy: 0.6447 - val_loss: 0.6567 - val_accuracy: 0.6117\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6208 - accuracy: 0.6463 - val_loss: 0.6935 - val_accuracy: 0.5960\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6230 - accuracy: 0.6428 - val_loss: 0.6628 - val_accuracy: 0.5977\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.6193 - accuracy: 0.6455 - val_loss: 0.6528 - val_accuracy: 0.6439\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6210 - accuracy: 0.6439 - val_loss: 0.6514 - val_accuracy: 0.6337\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.6202 - accuracy: 0.6479 - val_loss: 0.7245 - val_accuracy: 0.5389\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6202 - accuracy: 0.6458 - val_loss: 0.6698 - val_accuracy: 0.6201\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6215 - accuracy: 0.6459 - val_loss: 0.6560 - val_accuracy: 0.6192\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.6185 - accuracy: 0.6479 - val_loss: 0.6984 - val_accuracy: 0.5642\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6221 - accuracy: 0.6464 - val_loss: 0.7044 - val_accuracy: 0.5807\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6178 - accuracy: 0.6475 - val_loss: 0.6197 - val_accuracy: 0.6636\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6171 - accuracy: 0.6479 - val_loss: 0.6857 - val_accuracy: 0.5879\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6166 - accuracy: 0.6508 - val_loss: 0.6514 - val_accuracy: 0.6431\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6159 - accuracy: 0.6508 - val_loss: 0.6887 - val_accuracy: 0.5992\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6198 - accuracy: 0.6505 - val_loss: 0.6129 - val_accuracy: 0.6774\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6175 - accuracy: 0.6454 - val_loss: 0.6558 - val_accuracy: 0.6282\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6165 - accuracy: 0.6499 - val_loss: 0.6766 - val_accuracy: 0.5927\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6179 - accuracy: 0.6514 - val_loss: 0.6818 - val_accuracy: 0.5830\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6161 - accuracy: 0.6512 - val_loss: 0.6684 - val_accuracy: 0.6083\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6159 - accuracy: 0.6527 - val_loss: 0.6624 - val_accuracy: 0.6260\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6161 - accuracy: 0.6513 - val_loss: 0.6811 - val_accuracy: 0.6050\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6158 - accuracy: 0.6486 - val_loss: 0.6636 - val_accuracy: 0.6247\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6149 - accuracy: 0.6491 - val_loss: 0.6932 - val_accuracy: 0.5950\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6148 - accuracy: 0.6526 - val_loss: 0.6772 - val_accuracy: 0.6056\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6140 - accuracy: 0.6518 - val_loss: 0.6497 - val_accuracy: 0.6422\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6149 - accuracy: 0.6512 - val_loss: 0.7158 - val_accuracy: 0.5560\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6175 - accuracy: 0.6454 - val_loss: 0.6417 - val_accuracy: 0.6488\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6129 - accuracy: 0.6506 - val_loss: 0.6872 - val_accuracy: 0.6025\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6137 - accuracy: 0.6541 - val_loss: 0.6495 - val_accuracy: 0.6113\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.6117 - accuracy: 0.6529 - val_loss: 0.6136 - val_accuracy: 0.6812\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6119 - accuracy: 0.6562 - val_loss: 0.6578 - val_accuracy: 0.6342\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6112 - accuracy: 0.6584 - val_loss: 0.6876 - val_accuracy: 0.5908\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6132 - accuracy: 0.6505 - val_loss: 0.6872 - val_accuracy: 0.6043\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6095 - accuracy: 0.6600 - val_loss: 0.6651 - val_accuracy: 0.6315\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6115 - accuracy: 0.6527 - val_loss: 0.6295 - val_accuracy: 0.6758\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6107 - accuracy: 0.6548 - val_loss: 0.7075 - val_accuracy: 0.5850\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6113 - accuracy: 0.6527 - val_loss: 0.5864 - val_accuracy: 0.7175\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6078 - accuracy: 0.6566 - val_loss: 0.6863 - val_accuracy: 0.5968\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6091 - accuracy: 0.6544 - val_loss: 0.7122 - val_accuracy: 0.5976\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 2s 154ms/step - loss: 0.6098 - accuracy: 0.6539 - val_loss: 0.6620 - val_accuracy: 0.6329\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6101 - accuracy: 0.6532 - val_loss: 0.6801 - val_accuracy: 0.6243\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6072 - accuracy: 0.6559 - val_loss: 0.6678 - val_accuracy: 0.6288\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6071 - accuracy: 0.6589 - val_loss: 0.6451 - val_accuracy: 0.6458\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6050 - accuracy: 0.6622 - val_loss: 0.7359 - val_accuracy: 0.5703\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6069 - accuracy: 0.6600 - val_loss: 0.6532 - val_accuracy: 0.6433\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6050 - accuracy: 0.6594 - val_loss: 0.6661 - val_accuracy: 0.6223\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6046 - accuracy: 0.6626 - val_loss: 0.6460 - val_accuracy: 0.6409\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6070 - accuracy: 0.6580 - val_loss: 0.6502 - val_accuracy: 0.6609\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6075 - accuracy: 0.6569 - val_loss: 0.6778 - val_accuracy: 0.5982\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6041 - accuracy: 0.6581 - val_loss: 0.6594 - val_accuracy: 0.6357\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6059 - accuracy: 0.6560 - val_loss: 0.6634 - val_accuracy: 0.6431\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6043 - accuracy: 0.6596 - val_loss: 0.7492 - val_accuracy: 0.5618\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6054 - accuracy: 0.6539 - val_loss: 0.6791 - val_accuracy: 0.6272\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6025 - accuracy: 0.6638 - val_loss: 0.6707 - val_accuracy: 0.6238\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.6024 - accuracy: 0.6613 - val_loss: 0.6653 - val_accuracy: 0.6254\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6021 - accuracy: 0.6669 - val_loss: 0.6645 - val_accuracy: 0.6419\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6002 - accuracy: 0.6643 - val_loss: 0.7067 - val_accuracy: 0.5923\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.6007 - accuracy: 0.6666 - val_loss: 0.7091 - val_accuracy: 0.6000\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6048 - accuracy: 0.6607 - val_loss: 0.6672 - val_accuracy: 0.6466\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6035 - accuracy: 0.6592 - val_loss: 0.7170 - val_accuracy: 0.6094\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 0.6008 - accuracy: 0.6620 - val_loss: 0.6669 - val_accuracy: 0.6280\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.5998 - accuracy: 0.6656 - val_loss: 0.6710 - val_accuracy: 0.6178\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 2s 155ms/step - loss: 0.6039 - accuracy: 0.6612 - val_loss: 0.6890 - val_accuracy: 0.6041\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 3s 159ms/step - loss: 0.6007 - accuracy: 0.6620 - val_loss: 0.6436 - val_accuracy: 0.6665\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6007 - accuracy: 0.6626 - val_loss: 0.6556 - val_accuracy: 0.6404\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.5987 - accuracy: 0.6642 - val_loss: 0.6620 - val_accuracy: 0.6469\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.6034 - accuracy: 0.6573 - val_loss: 0.7156 - val_accuracy: 0.5578\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.6023 - accuracy: 0.6614 - val_loss: 0.6962 - val_accuracy: 0.5973\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5990 - accuracy: 0.6662 - val_loss: 0.6733 - val_accuracy: 0.6540\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 2s 156ms/step - loss: 0.6014 - accuracy: 0.6604 - val_loss: 0.6153 - val_accuracy: 0.6868\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.6012 - accuracy: 0.6636 - val_loss: 0.7327 - val_accuracy: 0.5660\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.5982 - accuracy: 0.6608 - val_loss: 0.6727 - val_accuracy: 0.6264\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.5975 - accuracy: 0.6652 - val_loss: 0.7102 - val_accuracy: 0.6139\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5997 - accuracy: 0.6627 - val_loss: 0.6631 - val_accuracy: 0.6375\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 0.6002 - accuracy: 0.6617 - val_loss: 0.6802 - val_accuracy: 0.6333\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.5965 - accuracy: 0.6699 - val_loss: 0.6823 - val_accuracy: 0.6355\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5971 - accuracy: 0.6627 - val_loss: 0.7369 - val_accuracy: 0.6015\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5965 - accuracy: 0.6644 - val_loss: 0.7154 - val_accuracy: 0.5989\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.6001 - accuracy: 0.6619 - val_loss: 0.6329 - val_accuracy: 0.6692\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5957 - accuracy: 0.6681 - val_loss: 0.7021 - val_accuracy: 0.6066\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5925 - accuracy: 0.6708 - val_loss: 0.6307 - val_accuracy: 0.6710\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.5954 - accuracy: 0.6671 - val_loss: 0.7350 - val_accuracy: 0.5771\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5894 - accuracy: 0.6723 - val_loss: 0.7168 - val_accuracy: 0.5903\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.5953 - accuracy: 0.6716 - val_loss: 0.6596 - val_accuracy: 0.6509\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 0.5951 - accuracy: 0.6681 - val_loss: 0.6915 - val_accuracy: 0.6256\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5912 - accuracy: 0.6709 - val_loss: 0.7020 - val_accuracy: 0.6221\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.5892 - accuracy: 0.6719 - val_loss: 0.6927 - val_accuracy: 0.6266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d1a378ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHHedZofQZQ7",
        "outputId": "cc98e47d-31e9-4f9a-8e16-140488b2bfa6"
      },
      "source": [
        "y_train_preds = model.predict([X_train, X_train_con])[:,0]\n",
        "y_valid_preds = model.predict([X_valid, X_valid_con])[:,0]\n",
        "\n",
        "print('LSTM Classifier')\n",
        "print('Training:')\n",
        "model_train_auc, model_train_accuracy, model_train_recall, model_train_precision, model_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
        "print('Validation:')\n",
        "model_valid_auc, model_valid_accuracy, model_valid_recall, model_valid_precision, model_valid_specificity = print_report(y_valid,y_valid_preds, thresh)\n",
        "\n",
        "#Achieve slightly better results than our GBM"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM Classifier\n",
            "Training:\n",
            "AUC:0.812\n",
            "accuracy:0.722\n",
            "recall:0.684\n",
            "precision:0.740\n",
            "specificity:0.759\n",
            "prevalence:0.500\n",
            " \n",
            "Validation:\n",
            "AUC:0.641\n",
            "accuracy:0.630\n",
            "recall:0.569\n",
            "precision:0.167\n",
            "specificity:0.637\n",
            "prevalence:0.113\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}